{
    "id": "ad1b235f-06a6-4d86-b047-b1611dfeb05c",
    "relatedPaper": 2,
    "context": {
        "metadata": {
            "titleEn": "SinoLC-1: The first 1-meter resolution national-scale land-cover map of China",
            "description": "SinoLC-1: The 1-meter resolution national-scale land cover map of China is the first land-cover product with a national scale coverage in China and a spatial resolution of 1.07 meters. The product is built based on a weakly-supervised deep learning framework. The framework combines existing low-resolution labels (10-meter land cover products),  Open Street Map (OSM) vector data, and very-high-resolution remote sensing data (1-meter Google Earth image) as training data. The framework achieves efficient large-scale land mapping tasks by fully mining reliable annotation information in 10-meter land cover products, combined with the fine texture information of 1-meter images, and processing data of about 73TB. At the same time, it completely gets rid of the manual annotating process. The data has been validated with over 100,000 sample points, and its overall accuracy is 73.61%. Compared with the statistical data of the third national land survey report, the overall misestimation rate of 6.4% is 6.4%.",
            "instructions": "The product is grouped by city tiles in the GeoTIFF format, which are packaged in provincial administrative region folders and stored as “.zip” files. Each city tile is named “G_P_C.tif,” where “G” explains the geographical region (south, central, east, north, northeast, northwest, and northeast of China) information, “P” explains the provincial administrative region information, and “C” explains the city name. For example, the 1-meter land-cover map for Wuhan City, Hubei Province is named “Central_Hubei_Wuhan.tif”.The dataset contains 11 land-cover types. The corresponding grayscale values for each type are as follows: Tree cover (2), Shrubland (3), Grassland (4), Cropland (5), Building (6), Traffic route (1), Barren and sparse vegetation (7), Snow and ice (8), Water (9), Wetland (10), Moss and lichen(12). ",
            "east": 135.05,
            "west": 73.33,
            "south": 3.51,
            "north": 53.33,
            "startTime": "2002-12-01 14:24:51",
            "endTime": "2021-12-01 14:24:51",
            "fileSize": 157220364446.0,
            "cstr": null,
            "doi": "10.5281/zenodo.7707461",
            "dataFormat": null,
            "license": "1"
        },
        "authorList": [
            {
                "nameEn": "LI Zhuohong",
                "unitEn": "Wuhan University"
            },
            {
                "nameEn": "ZHANG Hongyan",
                "unitEn": "China University of Geosciences"
            }
        ],
        "literatureList": [
            {
                "titleEn": "SinoLC-1: the first 1-meter resolution national-scale land-cover map of China created with the deep learning framework and open-access data",
                "referenceEn": "Li, Z., He, W., Cheng, M., Hu, J., Yang, G., & Zhang, H. (2023). SinoLC-1: the first 1-meter resolution national-scale land-cover map of China created with the deep learning framework and open-access data. Earth System Science Data, 2023, 1-38. https://doi.org/10.5194/essd-2023-87"
            },
            {
                "titleEn": "Breaking the resolution barrier: A low-to-high network for large-scale high-resolution land-cover mapping using low-resolution labels",
                "referenceEn": "Li, Z., Zhang, H., Lu, F., Xue, R., Yang, G., & Zhang, L. (2022). Breaking the resolution barrier: A low-to-high network for large-scale high-resolution land-cover mapping using low-resolution labels. ISPRS Journal of Photogrammetry and Remote Sensing, 192, 244-267.https://doi.org/10.1016/j.isprsjprs.2022.08.008"
            }
        ],
        "keywordStandList": [
            {
                "nameEn": "Remote Sensing Technology"
            },
            {
                "nameEn": "Terrestrial Surface"
            }
        ],
        "themeList": [
            {
                "nameEn": "Image Processing"
            },
            {
                "nameEn": "Land Cover"
            },
            {
                "nameEn": "Land Use/Land Cover"
            },
            {
                "nameEn": "Land cover"
            },
            {
                "nameEn": "Remote Sensing Product"
            },
            {
                "nameEn": "Remote Sensing Technology"
            }
        ],
        "placeKeywordList": [
            {
                "keywordEn": "China"
            }
        ],
        "temporalKeywordList": [
            {
                "keywordEn": "2002-2021",
                "type": "temporal"
            }
        ],
        "fundVOList": [
            {
                "titleEn": "Remote sensing precise monitoring and security warning platform for key coastal areas"
            }
        ],
        "projectList": [
            {
                "titleEn": "National Tibetan Plateau / Third Pole Environment Data Center"
            }
        ],
        "relatedDataList": [
            {
                "titleEn": "Human activity parameters in Qilian Mountain area (V1.0)"
            },
            {
                "titleEn": "Qilian Mountain comprehensive observation network: Plant diversity monitoring in Qilian Mountain (plant survey data - 2018)"
            },
            {
                "titleEn": "Daily MODIS-based land surface evapotranspiration dataset in Qilian Mountain Area (ETHi-merge V1) (2018)"
            },
            {
                "titleEn": "The land cover/use data in key areas of the Qilian Mountain (2018)"
            },
            {
                "titleEn": "Qilian Mountains integrated observatory network: Dataset of Heihe integrated observatory network (phenology camera observation dataset of Sidaoqiao superstation, 2018)"
            },
            {
                "titleEn": "Qilian Mountains integrated observatory network: Dataset of Heihe integrated observatory network (leaf area index of Sidaoqiao, 2018)"
            },
            {
                "titleEn": "Qilian Mountains integrated observatory network: Dataset of Heihe integrated observatory network (Leaf area index of Daman Superstation, 2018)"
            },
            {
                "titleEn": "Water index in the Qilian Mountain Area in 2018 "
            },
            {
                "titleEn": "Qilian Mountains integrated observatory network: Dataset of Heihe integrated observatory network (phenology camera observation data set of mixed forest superstation, 2018)"
            },
            {
                "titleEn": "Qilian Mountains integrated observatory network: Dataset of Heihe integrated observatory network (an observation system of meteorological elements gradient of Sidaoqiao superstation, 2018)"
            }
        ]
    },
    "extract_pdfs_data": [
        {
            "background": [
                "Large-scale high-resolution land-cover mapping is a way to comprehend the Earth’s surface and resolve the ecological and resource challenges facing humanity. High-resolution (≤1 m) remotely sensed images can now be captured more easily, with wider coverage, as sensors and satellites develop. Nevertheless, the synchronous renewal of land-cover maps is still challenging when using the common land-cover mapping methods, due to the requirement for high-resolution land-cover labels. Abundant low-resolution (∼30 m) land-cover products are available for use as alternative label sources, but the resolution gap between these products and the growing volume of high-resolution imagery is a barrier yet to be overcome. Mapping the land-cover situation can not only provide us with the appearance features of the natural landscape and informative descriptions of human development, but it also allows us to indirectly monitor biodiversity loss, soil degradation, and hydrological changes, thus meeting the urgent demands for the formulation of land-use policies and environmental governance plans. Meanwhile, as an inevitable consequence of construction activities, natural disasters, and climate change acting upon the geomorphic environment, land-cover maps rapidly fall out of date and must be constantly updated. With the maturation and development of airborne and spaceborne remote sensing platforms, growing volumes of up-to-date remotely sensed imagery with a high spatial resolution are now available for mapping the land surface both precisely and periodically. Therefore, exploring the use of appropriate geospatial data and mapping algorithms to efficiently update and refine the large-scale land-cover maps with a high resolution has great significance for the long-term development of human society."
            ],
            "research objective": [
                "In this paper, to break through this obstacle, we propose a low-to-high network (L2HNet) to automatically generate high-resolution land-cover maps from high-resolution images by taking only low-resolution land-cover products as the training labels, thus getting rid of the requirement for finely labeled samples during the large-scale map updating process."
            ],
            "challenges": [
                "Nevertheless, the training process for the common deep learning methods is highly reliant on a lot of high-precision labeled data, which are generally produced for specific needs through laborious and time-consuming manual annotation, thus severely restricting the mapping coverage of these methods. These findings suggest that the existing LR labels cannot easily provide reliable supervision information for the large-scale HR mapping task, and it is still a challenge to directly accomplish this task without using any HR labels or ancillary information. However, this approach requires a non-end-to-end redundant iterative process, which costs a lot of time and requires a large amount of computing resources for the large-scale applications."
            ],
            "methods": [
                "Firstly, to obtain the mapping results with rich details, we propose a resolution-preserving (RP) backbone that contains parallel multi-scale convolutional layers for extracting the high-resolution features from the images. Furthermore, to settle the label noise issue caused by the mismatched resolution, a confident area selection (CAS) module and a low-to-high (L2H) loss function, with weak and unsupervised strategies, are designed for obtaining reliable supervision information from the coarse labels."
            ],
            "dataset": [
                "The datasets used in this study covered two large-scale areas in the United States. Firstly, the Chesapeake Bay watershed, which is the largest bay of the United States, was chosen for conducting the quantitative experiments. As shown in Fig. 1, the watershed covers an area of roughly 160,000 km 2, and contains six administrative states, which are the state of Maryland (ML), Virginia (VA), Pennsylvania (PA), New York (NY), Delaware (DE), and West Virginia (WV). The HR (1 m) aerial images, with the bands of red (R), green (G), blue (B), and near-infrared (NIR), were captured by the U.S. Department of Agriculture’s National Agriculture Imagery Program (NAIP) in 2011/2012. The LR (30 m) land-cover labels for 2011 were obtained from the USGS’s National Land Cover Database (NLCD) (Wickham et al., 2017) in level II classification hierarchy, and were reprojected by nearest-neighbor upsampling to align with the NAIP imagery. The HR (1 m) ground references for the quantitative assessment were provided by the Chesapeake Bay Conservancy Land Cover (CCLC) project, which were created based on 1-m NAIP imagery and LiDAR elevation data with six land-cover classes. Furthermore, the ground references were generated through machine learning methods with manual corrections and reported an average accuracy of 88.5% in each state. In addition, the dataset was organized according to the work of Robinson et al. (2019), where a total of 732 non-overlapping tiles were partially sampled from the six states in the Chesapeake Bay watershed, with each tile covering an area of roughly 6000 m × 7500 m. Secondly, in order to further illustrate the practical performance of the L2HNet framework over an intact area with more detailed land-cover categories, the entire state of Maryland, as the core area of Chesapeake Bay with a coverage of 33,872 km 2, was chosen for conducting the practical HR land-cover mapping application, where the raw 30-m resolution NLCD products with the original level II classification hierarchy were directly employed as the label sources. In more detail, the Maryland dataset, which was provided by the Image Analysis and Data Fusion Technical Committee (IADF TC) of IEEE GRSS in 2021, consists of 2250 non-overlapping tiles, with each tile covering an area of 3880 m × 3880 m. For the Maryland dataset, as shown in Fig. 2, the data sources were aligned pairs of NAIP 1-m resolution images and NLCD 30-m resolution labels captured in the year of 2013."
            ],
            "findings": [
                "The experimental results obtained for six administrative states located in the Chesapeake Bay watershed of the United States show that L2HNet outperforms several of the state-of-the-art methods and the mainstream land-cover mapping methods in creating 1-m resolution land-cover maps by taking 30-m resolution land-cover products as training labels. As a further application, L2HNet was also adopted to produce the first 1-m resolution land-cover map with level II classification hierarchy for the entire state of Maryland in the United States, which covers an area of about 33,872 km²."
            ]
        },
        {
            "background": [
                "In China, the demand for a more precise perception of the national land surface has become most urgent given the pace of development and urbanization. Constructing a very-high-resolution (VHR) land-cover dataset for China with national coverage, however, is a non-trivial task and thus, an active area of research impeded by the challenges of image acquisition, manual annotation, and computational complexity. As a basic earth observation application, land-cover mapping enables investigating human and nonhuman activities that shape the national landscape. Researchers and decision makers use the insights from the land-cover maps to assist communities and governments achieve Sustainable Development Goals. The past few decades have witnessed tremendous advancements in the spatial resolution of land-cover mapping products because remote-sensing images with finer spatial resolution can be acquired more easily. Very-high-resolution (VHR) imagery in particular, typically finer than 3 m/pixel, reveals land-cover objects at an ever finer granularity providing a clearer, more detailed picture of the situation on the ground. These VHR land-cover datasets are becoming increasingly ubiquitous in numerous large-scale research and application domains, such as agriculture, urbanization, and ecology. However, the VHR land-cover map with national coverage is still unavailable in China, hindering effective policy formulation and efficient resource allocation. Over the past 40 years, numerous satellite missions have been launched to improve the knowledge of Earth’s resources and monitor natural phenomena. With the continuous updating of airborne and space-borne platforms, the spatial resolution of the available remote-sensing images has undergone rapid increments of change. Nevertheless, due to the low orbit of the VHR image-captured platforms, the corresponding VHR land-cover products generally have a smaller coverage that is insufficient to cover entire China. Furthermore, even if the national-scale VHR imagery can be obtained by combining different image sources, the immense data volumes, laborious annotations, and onerous processes are still the main obstacles for the national-scale VHR land-cover mapping. Thus, current available land-cover datasets for China lack either a fine spatial resolution or nationwide coverage. For global-scale LR, MR, and HR land-cover products, the image sources (i.e., MODIS, Landsat, and Sentinel) are commonly free access and contain massive spectral information but relatively low spatial context than VHR imagery. Therefore, pixel-based machine learning algorithms, for example, support vector machine, decision tree, and random forest (RF), are usually adopted to produce acceptable results. Recently, with the blossoming of deep learning techniques, many studies have conducted deep learning-based models for producing VHR land-cover datasets. However, existing deep learning methods rely on well-labeled data, which are time consuming and laborious to annotate. This limitation has created a large obstacle preventing the production of a national-scale land-cover map."
            ],
            "research objective": [
                "To overcome these limitations, in this paper, a deep learning-based low-cost framework is presented to create the first 1-meter land-cover map for entire China, called SinoLC-1, by using freely available 1-meter Google Earth imagery, open-access 10-meter GLC products, and Open Street Map (OSM) as input data. The produced SinoLC1 dataset is the first 1-meter resolution and currently the highest resolution land-cover product that covers all of China."
            ],
            "challenges": [
                "Constructing a very-high-resolution (VHR) land-cover dataset for China with national coverage, however, is a non-trivial task and thus, an active area of research impeded by the challenges of image acquisition, manual annotation, and computational complexity. The VHR land-cover map with national coverage is still unavailable in China, hindering effective policy formulation and efficient resource allocation. Due to the low orbit of the VHR image-captured platforms, the corresponding VHR land-cover products generally have a smaller coverage that is insufficient to cover entire China. Furthermore, even if the national-scale VHR imagery can be obtained by combining different image sources, the immense data volumes, laborious annotations, and onerous processes are still the main obstacles for the national-scale VHR land-cover mapping. However, existing deep learning methods rely on well-labeled data, which are time consuming and laborious to annotate. This limitation has created a large obstacle preventing the production of a national-scale land-cover map. One of the major limitations to the production of SinoLC-1 was the uneven temporal coverage of Google Earth images. Although Google Earth is a low-cost source to acquire nationwide coverage VHR images, the uneven temporal coverage of the images can affect the uniformity of the land-cover products."
            ],
            "methods": [
                "To construct the image database for producing SinoLC-1, the imagery of the “December 2021” version was collected according to every provincial administrative region border of China and cropped into the size of 6000 × 6000 pixels as the basic storage tile. The total storage size of imagery with the band of red, green, and blue was about 73.25 TB, covering ~9,600,000 km2 land surface area of China. To collect reliable training pairs for the national-scale VHR land-cover mapping process, 98 municipal-level areas were selected from the 34 provincial administrative regions of China. In every selected municipal-level area, the data were cropped into numerous non-overlapped tiles with the size of 6000 ×6000 pixels. In each tile, the training pairs were constructed by five types of data, which included three 10-meter GLC products, the OSM, and the 1.07-meter-resolution Google Earth imagery. To process the resolution-mismatched training pairs and realize automatic national-scale VHR land-cover mapping for China jointly, an low-to-high network (L2HNet) was applied, which has been proposed in our previous work (Li et al., 2022) and has reported state-of-the-art performance compared with the mainstream methods in the low-to-high land-cover mapping task. Based on the procedure, three large computing servers including 8 NVIDIA GeForce RTX 3090 GPUs and a large storage server were employed to conduct the mapping and merging of the SinoLC-1 in parallel. Processing the whole imagery with a total storage size of about 73.25 TB to obtain the final results of the SinoLC-1 land-cover product covering ~9,600,000 km2 area of China took about 10 months."
            ],
            "dataset": [
                "The VHR optical imagery was collected from the open-access Google Earth images at level 18, which approximately corresponds to a 1.07-meter resolution. The total storage size of imagery with the band of red, green, and blue was about 73.25 TB, covering ~9,600,000 km2 land surface area of China. Concretely, the land-cover labeled data were collected from three open-access 10-meter GLC products, namely, FROM_GLC10, ESRI world cover, and ESA_WorldCover v100. FROM_GLC10 was produced by using Sentinel-2A imagery, which reported an overall accuracy of 73% on a global scale. ESRI world cover (abbreviated as ESRI_GLC10) was produced based on Sentinel-2 imagery and reported an overall accuracy of 85%. ESA_WorldCover v100 (abbreviated as ESA_GLC10) was produced by using Sentinel-1 and Sentinel-2 data, and reported an overall accuracy of 74%."
            ],
            "findings": [
                "The validation results showed SinoLC-1 achieved an overall accuracy of 73.61% and a kappa coefficient of 0.6595. Validations for every provincial region further indicated the accuracy of this dataset across whole China. Furthermore, the statistical validation results indicated SinoLC-1 conformed closely to the official survey reports. These results indicated SinoLC-1 had the highest spatial resolution, the most accurate land-cover edges, and the finest landscape details. The produced SinoLC1 dataset is the first 1-meter resolution and currently the highest resolution land-cover product that covers all of China. Qualitative comparisons revealed the SinoLC-1 product with the highest spatial resolution yielded the most accurate land-cover edges, indicating the finest landscape details compared with five other widely used products. Quantitative assessments found the validation results derived from over 100,000 samples indicate SinoLC-1 achieved an O.A. of 73.61% and a kappa coefficient of 0.6595 across China. The validation results of every geographical region indicated an acceptable accuracy distribution all around China. Furthermore, the statistical validation results indicated SinoLC-1 highly conforms to the official survey reports according to the government data."
            ]
        }
    ],
    "query": [
        {
            "Verification": [
                {
                    "Question": "Is it possible to create a high-resolution land-cover map using only low-resolution land-cover products as training labels?",
                    "Answer": "Yes",
                    "Level": "C6(Creating)"
                },
                {
                    "Question": "Can the application of a low-to-high network overcome the challenges of using resolution-mismatched training pairs in large-scale land-cover mapping?",
                    "Answer": "Yes",
                    "Level": "C5(Evaluating)"
                }
            ]
        },
        {
            "Disjunctive": [
                {
                    "Question": "Are the methods for high-resolution land-cover mapping more reliant on pixel-based machine learning algorithms, deep learning models, or a combination of both?",
                    "Answer": "deep learning models",
                    "Level": "C5(Evaluating)"
                }
            ]
        },
        {
            "Concept Completion": [
                {
                    "Question": "What data collection methods are used to construct a high-resolution land-cover map of China?",
                    "Answer": "Google Earth imagery, GLC products, Open Street Map data",
                    "Level": "C1(Remembering)"
                },
                {
                    "Question": "What are the main challenges faced in creating a very-high-resolution land-cover dataset for China?",
                    "Answer": "image acquisition difficulties",
                    "Level": "C4(Analyzing)"
                },
                {
                    "Question": "Where are the high-resolution aerial images used in land-cover mapping experiments captured?",
                    "Answer": "Chesapeake Bay watershed",
                    "Level": "C1(Remembering)"
                }
            ]
        },
        {
            "Example": [
                {
                    "Question": "Can you provide an example of a data collection method that addresses the challenge of acquiring high-resolution land-cover labels for large-scale mapping?",
                    "Answer": "A notable method involves the use of low-resolution land-cover products as training labels to generate high-resolution land-cover maps. This approach was implemented using a low-to-high network (L2HNet) that eliminates the need for finely labeled samples, thereby facilitating large-scale mapping with high-resolution outputs.",
                    "Level": "C2(Understanding)"
                }
            ]
        },
        {
            "Feature Specification": [
                {
                    "Question": "What are the key characteristics of high-resolution land-cover datasets that make them useful for ecological and resource management challenges?",
                    "Answer": "very-high-resolution imagery, finer than 3 meters per pixel",
                    "Level": "C4(Analyzing)"
                },
                {
                    "Question": "What are the primary challenges associated with collecting and processing very-high-resolution land-cover data at a national scale?",
                    "Answer": "image acquisition, manual annotation, computational complexity, low orbit, smaller coverage, multiple image sources, immense data volume, labor-intensive annotations, uneven temporal coverage",
                    "Level": "C4(Analyzing)"
                },
                {
                    "Question": "What specific features or methodologies are employed to handle resolution mismatches in large-scale land-cover mapping?",
                    "Answer": "resolution-preserving backbone, multi-scale convolutional layers, confident area selection module, low-to-high loss function, weak and unsupervised strategies",
                    "Level": "C4(Analyzing)"
                }
            ]
        },
        {
            "Quantification": [
                {
                    "Question": "What is the total storage size of the imagery used in a large-scale high-resolution land-cover mapping project for a national-scale dataset?",
                    "Answer": "73.25 TB",
                    "Level": "C1(Remembering)"
                },
                {
                    "Question": "How many non-overlapping tiles were used in a dataset for conducting practical high-resolution land-cover mapping in a specific administrative state?",
                    "Answer": "2250",
                    "Level": "C1(Remembering)"
                },
                {
                    "Question": "What is the coverage area of the land surface mapped in a national-scale high-resolution land-cover mapping project?",
                    "Answer": "9,600,000 km²",
                    "Level": "C1(Remembering)"
                }
            ]
        },
        {
            "Definition": [
                {
                    "Question": "What is meant by 'low-to-high network (L2HNet)' in the context of land-cover mapping?",
                    "Answer": "In the context of land-cover mapping, a 'low-to-high network (L2HNet)' refers to a deep learning framework designed to generate high-resolution land-cover maps from high-resolution images by using only low-resolution land-cover products as training labels. This approach eliminates the need for finely labeled samples during large-scale map updating, making it more efficient for high-resolution mapping tasks.",
                    "Level": "C2(Understanding)"
                },
                {
                    "Question": "What challenges does 'resolution-mismatched training pairs' pose in the process of land-cover mapping?",
                    "Answer": "The challenge of 'resolution-mismatched training pairs' in land-cover mapping arises when there is a discrepancy between the resolution of training data and the high-resolution images being used for mapping. This mismatch can lead to label noise, making it difficult to obtain reliable supervision information, which in turn complicates the mapping process and affects the accuracy of the final land-cover maps.",
                    "Level": "C4(Analyzing)"
                }
            ]
        },
        {
            "Comparison": [
                {
                    "Question": "How do the data collection methods used in the creation of the SinoLC-1 dataset compare to those used in the Chesapeake Bay watershed study in terms of scale and resolution?",
                    "Answer": "The SinoLC-1 dataset collection utilized 1-meter resolution imagery from Google Earth, covering approximately 9,600,000 km² of China's land surface, which was processed to create a national-scale land-cover map. In contrast, the Chesapeake Bay watershed study used 1-meter aerial images from the NAIP program, focusing on a specific area of roughly 160,000 km² in the United States. The SinoLC-1 dataset was developed using three 10-meter GLC products and Open Street Map data as training labels, while the Chesapeake Bay study used 30-meter NLCD products for training.",
                    "Level": "C2(Understanding)"
                },
                {
                    "Question": "In what ways do the resolution-preserving techniques applied in the SinoLC-1 and Chesapeake Bay watershed datasets differ, and how does this affect the accuracy of the resulting land-cover maps?",
                    "Answer": "Both the SinoLC-1 and Chesapeake Bay watershed datasets employed methods to address the resolution mismatch between high-resolution images and low-resolution labels. The SinoLC-1 utilized a low-to-high network (L2HNet) to automatically generate high-resolution maps, achieving an overall accuracy of 73.61%. Similarly, the Chesapeake Bay study used a resolution-preserving backbone to extract high-resolution features, with the resulting maps showing improved accuracy over several state-of-the-art methods. Despite similar approaches, the scale of data and specific methods like confident area selection (CAS) module in the Chesapeake Bay study contributed to different accuracy outcomes and application challenges.",
                    "Level": "C4(Analyzing)"
                }
            ]
        },
        {
            "Interpretation": [
                {
                    "Question": "How can the integration of low-resolution land-cover products as training labels impact the accuracy and efficiency of high-resolution land-cover mapping?",
                    "Answer": "The integration of low-resolution land-cover products as training labels can significantly enhance the efficiency of high-resolution land-cover mapping by reducing the dependency on finely labeled samples, which are often time-consuming and laborious to produce. This approach allows for the automatic generation of high-resolution land-cover maps, overcoming the resolution gap between available low-resolution products and high-resolution imagery, and facilitates large-scale map updating processes.",
                    "Level": "C5(Evaluating)"
                },
                {
                    "Question": "What are the implications of using open-access data sources like Google Earth imagery and Open Street Map for developing high-resolution land-cover maps?",
                    "Answer": "Using open-access data sources such as Google Earth imagery and Open Street Map provides a low-cost and comprehensive approach to obtaining very-high-resolution imagery for national-scale land-cover mapping. These sources enable researchers to overcome limitations associated with image acquisition and manual annotation, although challenges remain, such as the uneven temporal coverage of the images which can affect product uniformity.",
                    "Level": "C5(Evaluating)"
                },
                {
                    "Question": "In what ways do computational resources and processing time influence the scalability of national-scale high-resolution land-cover mapping projects?",
                    "Answer": "Computational resources and processing time are critical factors in the scalability of national-scale high-resolution land-cover mapping projects. The necessity for large computing servers and substantial storage to process immense data volumes, as seen in the processing of approximately 73.25 TB of imagery for nationwide coverage, highlights the challenges of computational complexity. Efficient use of these resources can significantly impact both the feasibility and the duration of such projects, as demonstrated by the 10-month processing timeframe.",
                    "Level": "C4(Analyzing)"
                }
            ]
        },
        {
            "Causal Antecedent": [
                {
                    "Question": "What factors contribute to the complexity and challenges of constructing a very-high-resolution land-cover dataset for national coverage?",
                    "Answer": "Constructing a very-high-resolution (VHR) land-cover dataset for national coverage involves challenges such as image acquisition, manual annotation, and computational complexity. The low orbit of VHR image-captured platforms results in smaller coverage insufficient to cover entire regions, and even if national-scale imagery is obtained, immense data volumes and laborious annotations pose significant obstacles.",
                    "Level": "C4(Analyzing)"
                },
                {
                    "Question": "Why is the synchronous renewal of high-resolution land-cover maps challenging when using common mapping methods?",
                    "Answer": "The synchronous renewal of high-resolution land-cover maps is challenging due to the requirement for high-resolution land-cover labels, which are often unavailable or difficult to acquire. The gap between abundant low-resolution land-cover products and high-resolution imagery creates a barrier that common methods struggle to overcome without relying on laborious manual annotation.",
                    "Level": "C4(Analyzing)"
                },
                {
                    "Question": "What causes the reliance on complex computing resources and extended processing times for large-scale high-resolution land-cover mapping?",
                    "Answer": "Large-scale high-resolution land-cover mapping requires complex computing resources and extended processing times due to the non-end-to-end redundant iterative processes involved in training deep learning methods. These processes demand significant time and computational power, especially when dealing with large-scale applications.",
                    "Level": "C4(Analyzing)"
                }
            ]
        },
        {
            "Causal Consequence": [
                {
                    "Question": "What are the potential consequences of using low-resolution land-cover products as training labels for high-resolution land-cover mapping?",
                    "Answer": "Using low-resolution land-cover products as training labels for high-resolution mapping can mitigate the need for finely labeled samples, allowing for large-scale map updates. However, it may introduce the challenge of label noise due to mismatched resolutions, which requires strategies like confident area selection and custom loss functions to obtain reliable supervision.",
                    "Level": "C5(Evaluating)"
                },
                {
                    "Question": "What are the implications of employing a deep learning-based low-cost framework on the production of high-resolution land-cover maps at a national scale?",
                    "Answer": "Employing a deep learning-based low-cost framework can facilitate the creation of high-resolution land-cover maps at a national scale by using freely available imagery and open-access data. This approach can overcome the limitations of manual annotation and improve coverage, but it still faces challenges like ensuring uniformity in the temporal coverage of imagery and managing extensive data processing requirements.",
                    "Level": "C5(Evaluating)"
                }
            ]
        },
        {
            "Goal Orientation": [
                {
                    "Question": "What objectives drive the development of a deep learning-based framework for generating high-resolution land-cover maps using low-resolution products as training labels?",
                    "Answer": "The objective is to overcome the requirement for finely labeled samples during the large-scale map updating process by proposing a low-to-high network (L2HNet) that automatically generates high-resolution land-cover maps from high-resolution images using only low-resolution land-cover products as training labels.",
                    "Level": "C4(Analyzing)"
                },
                {
                    "Question": "What challenges are addressed by employing open-access satellite imagery and weak supervision strategies in the production of nationwide high-resolution land-cover maps?",
                    "Answer": "The challenges addressed include the immense data volumes, laborious annotations, and computational complexity associated with acquiring and processing very-high-resolution imagery for nationwide coverage. Using open-access satellite imagery and weak supervision strategies reduces reliance on time-consuming manual annotations, facilitating the production of national-scale high-resolution land-cover maps.",
                    "Level": "C4(Analyzing)"
                }
            ]
        },
        {
            "Instrumental/Procedural": [
                {
                    "Question": "What are the procedural steps involved in constructing a very-high-resolution land-cover dataset using low-resolution labels as training data?",
                    "Answer": "The procedural steps involve using a deep learning-based low-to-high network (L2HNet) to automatically generate high-resolution land-cover maps from high-resolution images by taking only low-resolution land-cover products as training labels. This includes the use of a resolution-preserving backbone, a confident area selection module, and a low-to-high loss function. The process involves collecting and organizing high-resolution imagery and low-resolution labels, aligning them appropriately, and processing them through the network to achieve high-resolution mapping.",
                    "Level": "C3(Applying)"
                },
                {
                    "Question": "How can national-scale VHR land-cover mapping be conducted efficiently given the challenges of image acquisition and annotation?",
                    "Answer": "National-scale VHR land-cover mapping can be conducted efficiently by using freely available high-resolution imagery, such as Google Earth images, and combining them with open-access low-resolution land-cover products and auxiliary data like Open Street Map. The data are organized into non-overlapping tiles, and a low-to-high network is employed to process these tiles, allowing for automatic mapping without the need for laborious manual annotations. The process leverages parallel computing servers for efficient data handling and processing.",
                    "Level": "C6(Creating)"
                },
                {
                    "Question": "What methods are utilized to ensure reliable supervision information when dealing with mismatched resolution labels in large-scale land-cover mapping?",
                    "Answer": "Methods to ensure reliable supervision information include using a confident area selection module and a low-to-high loss function designed to handle label noise caused by mismatched resolutions. These components work within the low-to-high network framework, allowing the extraction of reliable supervision information from coarse labels. The approach uses weak and unsupervised strategies to manage the resolution mismatch and improve the accuracy of the high-resolution mapping results.",
                    "Level": "C4(Analyzing)"
                }
            ]
        },
        {
            "Enablement": [
                {
                    "Question": "What methodologies enable the generation of high-resolution land-cover maps from low-resolution land-cover products without the need for finely labeled samples?",
                    "Answer": "The L2HNet methodology enables the automatic generation of high-resolution land-cover maps from high-resolution images by using only low-resolution land-cover products as training labels. This method eliminates the need for finely labeled samples during the large-scale map updating process.",
                    "Level": "C6(Creating)"
                },
                {
                    "Question": "How does the integration of multi-scale convolutional layers in a deep learning framework facilitate the extraction of high-resolution features for land-cover mapping?",
                    "Answer": "The integration of parallel multi-scale convolutional layers in a deep learning framework, such as the resolution-preserving (RP) backbone, facilitates the extraction of high-resolution features from images, allowing for the generation of mapping results with rich details.",
                    "Level": "C4(Analyzing)"
                },
                {
                    "Question": "What resources and conditions enable the creation of a nationwide very-high-resolution land-cover dataset, considering the challenges of data volume and annotation in large-scale applications?",
                    "Answer": "The creation of a nationwide very-high-resolution land-cover dataset is enabled by using freely available 1-meter Google Earth imagery, open-access 10-meter GLC products, and Open Street Map (OSM) as input data. This approach overcomes challenges of data volume and manual annotation by utilizing deep learning techniques that do not rely on well-labeled data.",
                    "Level": "C6(Creating)"
                }
            ]
        },
        {
            "Expectation": [
                {
                    "Question": "Why might the resolution gap between low-resolution land-cover products and high-resolution imagery remain a significant obstacle in creating high-resolution land-cover maps?",
                    "Answer": "The resolution gap is a significant obstacle because existing low-resolution land-cover products cannot easily provide reliable supervision information for high-resolution mapping tasks. This gap makes it challenging to directly accomplish the task without using high-resolution labels or ancillary information, which are normally dependent on laborious and time-consuming manual annotation.",
                    "Level": "C4(Analyzing)"
                },
                {
                    "Question": "What might be the reasons for the challenges in acquiring a consistent national-scale very-high-resolution land-cover dataset for a country like China?",
                    "Answer": "Challenges include the low orbit of VHR image-captured platforms that results in smaller coverage, the immense data volumes, and the laborious annotations required. Even if national-scale VHR imagery is obtained by combining different sources, the uneven temporal coverage of images can affect the uniformity of the land-cover products, which complicates the task of creating a consistent national-scale dataset.",
                    "Level": "C4(Analyzing)"
                },
                {
                    "Question": "Why might existing deep learning methods struggle to efficiently produce national-scale land-cover maps without relying heavily on well-labeled data?",
                    "Answer": "Existing deep learning methods struggle because they rely on well-labeled data, which are time-consuming and laborious to annotate. This reliance creates a large obstacle to producing national-scale land-cover maps, as manual annotation is often not feasible for such large-scale datasets. The lack of finely labeled samples during the map updating process further restricts the mapping coverage and efficiency.",
                    "Level": "C4(Analyzing)"
                }
            ]
        },
        {
            "Judgmental": [
                {
                    "Question": "How would you evaluate the effectiveness of using low-resolution land-cover products as training labels for high-resolution land-cover mapping?",
                    "Answer": "The use of low-resolution land-cover products as training labels for high-resolution mapping is seen as an effective approach to overcome the challenge of high-precision labeled data dependency. This method allows for the creation of high-resolution land-cover maps by leveraging existing low-resolution datasets, thus reducing the need for labor-intensive manual annotation. The approach has been validated through successful implementations that achieved high spatial resolutions and accurate land-cover details, indicating its practical efficacy.",
                    "Level": "C5(Evaluating)"
                },
                {
                    "Question": "In your opinion, what are the main challenges faced in constructing a very-high-resolution land-cover dataset for a nation-wide scale, and how might these challenges be addressed?",
                    "Answer": "The main challenges in constructing a very-high-resolution land-cover dataset for national coverage include the massive data volumes, laborious annotations, computational complexity, and uneven temporal coverage of available imagery. Addressing these challenges may involve the use of deep learning frameworks that rely on available low-resolution data and open-access imagery, coupled with efficient computational strategies such as parallel processing using advanced GPU servers. These methods help manage data complexity and reduce the reliance on extensive manual annotations.",
                    "Level": "C5(Evaluating)"
                },
                {
                    "Question": "What is your assessment of the potential of using open-access imagery and existing global land-cover products for producing high-resolution land-cover maps?",
                    "Answer": "Open-access imagery and existing global land-cover products hold significant potential for producing high-resolution land-cover maps. They provide a cost-effective means of obtaining extensive coverage with relatively high accuracy. The integration of such data sources with advanced deep learning methods can yield detailed land-cover products with fine spatial resolution. Despite challenges such as resolution mismatches and data volume, the successful creation of national-scale maps with high accuracy underscores their utility and potential.",
                    "Level": "C5(Evaluating)"
                }
            ]
        },
        {
            "Assertion": [
                {
                    "Question": "I'm unsure about how low-resolution data can be effectively used to train models for high-resolution land-cover mapping without high-resolution labels.",
                    "Answer": "To overcome the resolution gap, a low-to-high network (L2HNet) is proposed, which uses low-resolution land-cover products as training labels to generate high-resolution maps. This approach includes a resolution-preserving backbone and a confident area selection module to handle label noise and extract high-resolution features from images.",
                    "Level": "C5(Evaluating)"
                },
                {
                    "Question": "I don't understand how such large volumes of image data can be processed efficiently for national-scale land-cover mapping.",
                    "Answer": "The processing of large volumes of image data for national-scale land-cover mapping is conducted using an efficient deep learning framework, specifically the L2HNet. The process is supported by high-performance computing infrastructure, including multiple NVIDIA GeForce RTX 3090 GPUs, allowing parallel processing to manage the 73.25 TB of data over 10 months.",
                    "Level": "C2(Understanding)"
                },
                {
                    "Question": "I can't make sense of how a dataset can ensure accuracy across such a vast and diverse geographic area.",
                    "Answer": "The accuracy of the land-cover dataset across a vast geographic area is ensured through validation against 100,000 samples and official survey reports. The dataset achieved an overall accuracy of 73.61% with a kappa coefficient of 0.6595, supported by qualitative comparisons and statistical validation that reflect its conformity to official data.",
                    "Level": "C4(Analyzing)"
                }
            ]
        },
        {
            "Request/Directive": [
                {
                    "Question": "Please explore various data collection methods that can be used to construct high-resolution land-cover maps and discuss their potential challenges.",
                    "Answer": "Data collection for high-resolution land-cover maps often involves using high-resolution remote sensing imagery, such as 1-meter resolution images from platforms like Google Earth. Open-access datasets like 10-meter GLC products (FROM_GLC10, ESA_WorldCover, and ESRI_GLC) and Open Street Map (OSM) can serve as training labels. Challenges include the need for manual annotation, computational complexity, and uneven temporal coverage of imagery, which can affect the consistency and accuracy of the land-cover maps.",
                    "Level": "C4(Analyzing)"
                },
                {
                    "Question": "Please analyze the methodological approaches to overcoming the resolution gap between low-resolution land-cover products and high-resolution imagery in large-scale mapping.",
                    "Answer": "One approach to bridging the resolution gap is using a low-to-high network (L2HNet) that automatically generates high-resolution land-cover maps from high-resolution images by utilizing low-resolution land-cover products as training labels. This method alleviates the need for finely labeled samples in large-scale mappings and addresses challenges such as the reliance on high-precision labeled data and computational resource demands.",
                    "Level": "C4(Analyzing)"
                },
                {
                    "Question": "Please discuss potential datasets that can serve as training labels for creating high-resolution land-cover maps and evaluate their effectiveness.",
                    "Answer": "Potential datasets for training labels include open-access 10-meter GLC products such as FROM_GLC10, ESRI world cover, and ESA_WorldCover, which are derived from Sentinel imagery. While these datasets provide a valuable resource, their effectiveness can vary, with reported accuracies of 73% to 85%. They offer a trade-off between accessibility and spatial context, and their resolution mismatch with high-resolution imagery remains a challenge to address.",
                    "Level": "C5(Evaluating)"
                }
            ]
        }
    ]
}