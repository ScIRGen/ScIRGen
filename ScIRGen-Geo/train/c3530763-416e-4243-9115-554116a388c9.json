{
    "id": "c3530763-416e-4243-9115-554116a388c9",
    "relatedPaper": 0,
    "context": {
        "metadata": {
            "titleEn": "Crawler data set of extreme drought historical events in 34 key node areas along the route of One Belt And One Road",
            "titleCn": "“一带一路”沿线34个关键节点区域极端干旱历史事件网络爬虫数据集",
            "description": "The extreme drought damage historical events data of the 34 key areas along One Belt One Road were collected from Internet. First, a Web crawler was coded by python language. Using several key words about extreme drought damage, web pages were then collected by Google and Baidu search engine. Last, important information about the extreme drought  events (e.g., place, time, affected area, affected population, count of death) were extracted from web pages. This data can be used for risk assessment of extreme drought in the 34 key areas along One Belt One Road.",
            "descriptionCn": "“一带一路”沿线34个关键节点区域极端干旱历史事件泛在网络数据是从互联网收集而来。该数据通过Python程序语言编写网络爬虫，通过调用谷歌和百度搜索引擎根据极端干旱事件的关键词获得网页信息，并对网页信息进行解析，提取事件发生的时间、地点以及事件概况、影响范围、受灾人数、死亡人数、网页地址等核心信息。该数据可用于极端事件中极端干旱的风险评估，从而为“一带一路”沿线关键节点和区域开展极端干旱风险研究提供重要支撑作用。",
            "instructions": "text",
            "instructionsCn": "文本形式",
            "east": 180.0,
            "west": -180.0,
            "south": -90.0,
            "north": 90.0,
            "startTime": "1917-01-11 00:00:00",
            "endTime": "2019-01-10 00:00:00",
            "fileSize": 1301741.0,
            "cstr": null,
            "doi": "",
            "dataFormat": null,
            "license": "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)"
        },
        "authorList": [
            {
                "nameCn": "葛咏",
                "nameEn": "GE Yong",
                "unitEn": "Institute of Geographic Sciences and Natural Resources Research, CAS",
                "unitCn": "中国科学院地理科学与资源研究所"
            },
            {
                "nameCn": "凌峰",
                "nameEn": "LING Feng",
                "unitEn": "",
                "unitCn": "中国科学院测量与地球物理研究所"
            }
        ],
        "literatureList": [
            {
                "titleCn": null,
                "titleEn": "How much more rain will global warming bring?",
                "referenceCn": null,
                "referenceEn": "Wentz, F.J., Ricciardulli, L., Hilburn, K., & Mears, C. (2007). How much more rain will global warming bring?. Science, 317(5835), 233-235."
            }
        ],
        "keywordStandList": [
            {
                "nameCn": "人地关系",
                "nameEn": "Human-nature Relationship"
            }
        ],
        "themeList": [
            {
                "nameCn": "自然灾害",
                "nameEn": "Natural Disaster"
            }
        ],
        "placeKeywordList": [
            {
                "keywordCn": "泛第三极",
                "keywordEn": "Pan-third pole"
            }
        ],
        "temporalKeywordList": [
            {
                "keywordCn": "1917-2018",
                "keywordEn": "1917-2018",
                "type": "temporal"
            }
        ],
        "fundVOList": null,
        "projectList": [
            {
                "titleCn": "国家青藏高原科学数据中心",
                "titleEn": "National Tibetan Plateau / Third Pole Environment Data Center"
            }
        ],
        "relatedDataList": [
            {
                "titleCn": "祁连山重点区域30m人类活动参数产品数据集（V1.0）",
                "titleEn": "Human activity parameters in Qilian Mountain area (V1.0)"
            },
            {
                "titleCn": "青藏高原1:100万行政边界数据（2017）",
                "titleEn": "Administrative boundaries data at 1:1000 000 scale over the Tibetan Plateau (2017)"
            },
            {
                "titleCn": "祁连山重点区域人类活动数据集 (2018)",
                "titleEn": "The human activity dataset in key area of Qilian Mountaion (2018)"
            },
            {
                "titleCn": "三极人口&GDP数据集（1970-2006）",
                "titleEn": "Three-pole population &GDP dataset (1970-2006)"
            },
            {
                "titleCn": "祁连山区域30m人类活动参数产品数据集（V1.0）（2018）",
                "titleEn": "Human activity parameters at Qilian Mountain Area (V1.0) (2018)"
            },
            {
                "titleCn": "祁连山区域30m人类活动参数产品数据集（V1.0）（1985-2017）",
                "titleEn": "Human activity parameters at Qilian Mountain Area (V1.0) (1985-2017)"
            },
            {
                "titleCn": "耦合模式比较计划第6阶段CNRM-CM6-1模式全球植被生产力月数据（1850-2014）",
                "titleEn": "Global vegetation productivity monthly data obtained by CNRM-CM6-1 mode of CMIP6 (1850-2014)"
            },
            {
                "titleCn": "青藏高原300米分辨率土壤侵蚀（水蚀）强度数据集（1992、2005、2015）",
                "titleEn": "Dataset of Soil  Erosion （water) Intensity with 300m resoluton in Tibetan Plateau (1992, 2005, 2015)"
            },
            {
                "titleCn": "可可西里-土地覆盖及植被类型地面验证点数据集",
                "titleEn": "Hoh Xil - land cover and vegetation type ground verification point dataset"
            },
            {
                "titleCn": "黄河源区-土地覆盖及植被类型地面验证点数据集",
                "titleEn": "Source region of Yellow River - land cover and vegetation type ground verification point dataset"
            }
        ]
    },
    "extract_pdfs_data": null,
    "query": {
        "Feature Specification": [
            {
                "QuestionEn": "What are the key attributes of data collected through web crawling for extreme drought events along the 'Belt and Road' key node areas?",
                "QuestionCn": "通过网络爬虫收集的关于“一带一路”关键节点地区极端干旱事件的数据的关键属性是什么？",
                "AnswerEn": "time of the event, location of the event, overview of the event, impact range, number of affected individuals, number of casualties, web address",
                "AnswerCn": "事件时间，事件地点，事件概述，影响范围，受影响人数，伤亡人数，网址",
                "Level": "C4(Analyzing)"
            }
        ],
        "Quantification": [
            {
                "QuestionEn": "How many key regions along the Belt and Road Initiative are included in a dataset focused on extreme drought events?",
                "QuestionCn": "在一个专注于极端干旱事件的数据集中，包含了多少个与“一带一路”倡议相关的关键区域？",
                "AnswerEn": "34",
                "AnswerCn": "34",
                "Level": "C1(Remembering)"
            }
        ],
        "Interpretation": [
            {
                "QuestionEn": "What insights can be drawn about the effectiveness of using web crawlers for collecting data on extreme drought events in key node regions along the 'Belt and Road' Initiative?",
                "QuestionCn": "关于在“一带一路”倡议的关键节点地区使用网络爬虫收集极端干旱事件数据的有效性，可以得出哪些见解？",
                "AnswerEn": "The use of web crawlers, implemented through Python and leveraging search engines like Google and Baidu, allows for the extraction of structured information such as event occurrence time, location, summary, impact scope, affected population, and casualties. This approach enables comprehensive data collection from internet sources, which can aid in the risk assessment of extreme drought events along the 'Belt and Road' Initiative's key node regions.",
                "AnswerCn": "通过使用网络爬虫，利用Python并借助谷歌和百度等搜索引擎，可以提取结构化信息，如事件发生时间、地点、摘要、影响范围、受影响人口和伤亡情况。这种方法能够从互联网来源全面收集数据，有助于对“一带一路”关键节点地区极端干旱事件的风险评估。",
                "Level": "C4(Analyzing)"
            }
        ],
        "Causal Antecedent": [
            {
                "QuestionEn": "What causes challenges in collecting comprehensive data on extreme drought events along the Belt and Road Initiative regions?",
                "QuestionCn": "导致在“一带一路”沿线地区收集极端干旱事件综合数据的挑战的原因是什么？",
                "AnswerEn": "Challenges in collecting comprehensive data on extreme drought events along the Belt and Road Initiative regions may arise from the complexity of extracting relevant information from internet sources using web crawling techniques. Difficulties can include accurately parsing and interpreting data from multiple websites, ensuring the coverage of all significant events, and dealing with inconsistent reporting of key details such as the event's impact, affected population, and specific locations. Additionally, reliance on search engines like Google and Baidu may introduce biases based on search algorithms and available content.",
                "AnswerCn": "在“一带一路”地区收集极端干旱事件的综合数据时，可能会面临一些挑战，这些挑战源于使用网络爬虫技术从互联网来源提取相关信息的复杂性。困难包括准确解析和解释来自多个网站的数据，确保覆盖所有重要事件，以及处理关键细节（如事件影响、受影响人口和具体地点）的不一致报告。此外，依赖于谷歌和百度等搜索引擎可能会引入基于搜索算法和可用内容的偏见。",
                "Level": "C4(Analyzing)"
            }
        ],
        "Causal Consequence": [
            {
                "QuestionEn": "What are the potential consequences of using web scraping techniques with search engines like Google and Baidu to collect data on historical extreme drought events in terms of data accuracy and comprehensiveness?",
                "QuestionCn": "使用网络爬虫技术从搜索引擎如谷歌和百度收集历史极端干旱事件数据的潜在后果包括数据准确性和全面性方面的问题。",
                "AnswerEn": "Using web scraping techniques with search engines like Google and Baidu to collect data on historical extreme drought events can lead to a dataset that provides detailed information on the timing, location, and impact of these events. However, the accuracy and comprehensiveness of the data depend heavily on the quality and reliability of the web pages from which the data is extracted. This method allows for a broad collection of data from various sources, but it may also introduce inconsistencies due to varying reporting standards and potential biases in online content. These factors can affect the risk assessment of extreme drought events along the 'Belt and Road' Initiative's key nodes and regions.",
                "AnswerCn": "使用网络爬虫技术从谷歌和百度等搜索引擎收集历史极端干旱事件的数据，可以生成一个提供这些事件时间、地点和影响的详细信息的数据集。然而，数据的准确性和全面性在很大程度上依赖于提取数据的网页的质量和可靠性。这种方法允许从各种来源广泛收集数据，但由于报告标准的差异和在线内容的潜在偏见，也可能引入不一致性。这些因素可能影响对“一带一路”倡议关键节点和地区极端干旱事件的风险评估。",
                "Level": "C5(Evaluating)"
            }
        ],
        "Goal Orientation": [
            {
                "QuestionEn": "What is the primary objective of collecting historical extreme drought event data from the internet for regions along the Belt and Road initiative?",
                "QuestionCn": "收集“一带一路”沿线地区历史极端干旱事件数据的主要目标是什么。",
                "AnswerEn": "The primary objective is to assess the risk of extreme drought events, thereby providing crucial support for research on extreme drought risk in key nodes and regions along the Belt and Road initiative.",
                "AnswerCn": "主要目标是评估极端干旱事件的风险，从而为“一带一路”倡议沿线关键节点和地区的极端干旱风险研究提供重要支持。",
                "Level": "C2(Understanding)"
            }
        ],
        "Instrumental/Procedural": [
            {
                "QuestionEn": "What are the procedural steps involved in using a web crawler to collect historical extreme drought event data from online sources along the Belt and Road key node regions?",
                "QuestionCn": "使用网络爬虫从在线来源收集“一带一路”关键节点地区历史极端干旱事件数据的程序步骤包括：\n\n1. 确定目标网站和数据源：识别与极端干旱事件相关的可靠网站和数据库，例如气象局、环境监测机构和学术研究网站。\n\n2. 设计爬虫架构：选择合适的编程语言和框架（如Python和Scrapy）来构建爬虫，设计爬虫的结构和功能。\n\n3. 确定数据抓取策略：明确需要抓取的数据类型（如事件日期、地点、干旱程度等），并制定抓取策略。\n\n4. 实现爬虫代码：编写代码以实现数据抓取，包括发送HTTP请求、解析HTML内容、提取所需数据等。\n\n5. 处理反爬虫机制：研究目标网站的反爬虫措施，并采取相应的策略（如设置请求间隔、使用代理等）以避免被封禁。\n\n6. 数据存储：选择合适的数据库或文件格式（如CSV、JSON、SQL等）来存储抓取到的数据。\n\n7. 数据清洗和预处理：对抓取的数据进行清洗和预处理，去除重复项、处理缺失值和格式化数据。\n\n8. 数据分析和可视化：对收集到的历史极端干旱事件数据进行分析，并使用可视化工具展示结果。\n\n9. 定期更新和维护：定期运行爬虫以获取最新数据，并对爬虫进行维护和更新，以适应网站结构的变化。\n\n10. 遵循法律法规：确保在数据抓取过程中遵循相关法律法规和网站的使用条款。",
                "AnswerEn": "To collect historical extreme drought event data from online sources along the Belt and Road key node regions, a web crawler is used. This process involves writing a program in Python to automate the data retrieval. The web crawler accesses Google and Baidu search engines and uses specific keywords related to extreme drought events to gather web page information. The collected data is then parsed to extract core information such as the time, location, event overview, impact range, number of affected people, number of deaths, and web page addresses. This approach enables the compilation of a comprehensive dataset for risk assessment of extreme droughts in these regions.",
                "AnswerCn": "为了收集“一带一路”关键节点地区的历史极端干旱事件数据，使用了网络爬虫。这个过程涉及用Python编写程序来自动化数据检索。网络爬虫访问Google和百度搜索引擎，并使用与极端干旱事件相关的特定关键词来收集网页信息。收集到的数据随后被解析，以提取核心信息，如时间、地点、事件概述、影响范围、受影响人数、死亡人数和网页地址。这种方法能够为这些地区的极端干旱风险评估编制一个全面的数据集。",
                "Level": "C3(Applying)"
            }
        ],
        "Enablement": [
            {
                "QuestionEn": "What technological advancements and data collection methods enable the comprehensive gathering of historical extreme drought events in key regions along the Belt and Road Initiative?",
                "QuestionCn": "哪些技术进步和数据收集方法能够全面收集“一带一路”关键地区的历史极端干旱事件？",
                "AnswerEn": "The use of Python programming language to develop web crawlers that leverage search engines like Google and Baidu enables the collection of web-based information. This approach allows for the extraction of crucial details such as the time, location, overview, affected areas, number of victims, and casualties related to historical extreme drought events.",
                "AnswerCn": "使用Python编程语言开发网络爬虫，利用谷歌和百度等搜索引擎，可以收集基于网络的信息。这种方法允许提取与历史极端干旱事件相关的重要细节，如时间、地点、概述、受影响地区、受害者人数和伤亡情况。",
                "Level": "C4(Analyzing)"
            }
        ]
    }
}